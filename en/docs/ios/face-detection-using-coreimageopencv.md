---
title: "Face Detection Using CoreImageOpenCV"
slug: "face-detection-using-coreimageopencv"
draft: false
images: []
weight: 9935
type: docs
toc: true
---

## Face and Feature Detection
**Objective-C**

Import the following to your ViewController

    #import <CoreImage/CoreImage.h>
    #import <CoreImage/CoreImage.h>
    #import <QuartzCore/QuartzCore.h>

Call the function

 

    [self faceDetector];

Function definition:

    -(void)faceDetector
    {
        // Load the picture for face detection
        UIImageView* image = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@"download.jpeg"]];
        
        // Draw the face detection image
        [self.view addSubview:image];
        
        // Execute the method used to markFaces in background
        [self performSelectorInBackground:@selector(markFaces:) withObject:image];
        
        // flip image on y-axis to match coordinate system used by core image
        [image setTransform:CGAffineTransformMakeScale(1, -1)];
        
        // flip the entire window to make everything right side up
        [self.view setTransform:CGAffineTransformMakeScale(1, -1)];
        
        
    }
Mark Face Function

    //Adds face squares and color masks to eyes and mouth
    -(void)markFaces:(UIImageView *)facePicture
    {
        // draw a CI image with the previously loaded face detection picture
        CIImage* image = [CIImage imageWithCGImage:facePicture.image.CGImage];
        
        // create a face detector - since speed is not an issue we'll use a high accuracy
        // detector
        CIDetector* detector = [CIDetector detectorOfType:CIDetectorTypeFace
                                                  context:nil options:[NSDictionary dictionaryWithObject:CIDetectorAccuracyHigh forKey:CIDetectorAccuracy]];
        
        // create an array containing all the detected faces from the detector
        NSArray* features = [detector featuresInImage:image];
        NSLog(@"Number of faces %d",[features count]);
        
        // we'll iterate through every detected face.  CIFaceFeature provides us
        // with the width for the entire face, and the coordinates of each eye
        // and the mouth if detected.  Also provided are BOOL's for the eye's and
        // mouth so we can check if they already exist.
        //    for (features in image)
        //    {
        for(CIFaceFeature* faceFeature in features)
        {
            // get the width of the face
            CGFloat faceWidth = faceFeature.bounds.size.width;
            
            // create a UIView using the bounds of the face
            UIView* faceView = [[UIView alloc] initWithFrame:faceFeature.bounds];
            
            // add a border around the newly created UIView
            faceView.layer.borderWidth = 1;
            faceView.layer.borderColor = [[UIColor redColor] CGColor];
            
            // add the new view to create a box around the face
            [self.view addSubview:faceView];
            
            if(faceFeature.hasLeftEyePosition)
            {
                // create a UIView with a size based on the width of the face
                UIView* leftEyeView = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.leftEyePosition.x-faceWidth*0.15, faceFeature.leftEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];
                // change the background color of the eye view
                [leftEyeView setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];
                // set the position of the leftEyeView based on the face
                [leftEyeView setCenter:faceFeature.leftEyePosition];
                // round the corners
                leftEyeView.layer.cornerRadius = faceWidth*0.15;
                // add the view to the window
                [self.view addSubview:leftEyeView];
            }
            
            if(faceFeature.hasRightEyePosition)
            {
                // create a UIView with a size based on the width of the face
                UIView* leftEye = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.rightEyePosition.x-faceWidth*0.15, faceFeature.rightEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];
                // change the background color of the eye view
                [leftEye setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];
                // set the position of the rightEyeView based on the face
                [leftEye setCenter:faceFeature.rightEyePosition];
                // round the corners
                leftEye.layer.cornerRadius = faceWidth*0.15;
                // add the new view to the window
                [self.view addSubview:leftEye];
            }
            
            if(faceFeature.hasMouthPosition)
            {
                // create a UIView with a size based on the width of the face
                UIView* mouth = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.mouthPosition.x-faceWidth*0.2, faceFeature.mouthPosition.y-faceWidth*0.2, faceWidth*0.4, faceWidth*0.4)];
                // change the background color for the mouth to green
                [mouth setBackgroundColor:[[UIColor greenColor] colorWithAlphaComponent:0.3]];
                // set the position of the mouthView based on the face
                [mouth setCenter:faceFeature.mouthPosition];
                // round the corners
                mouth.layer.cornerRadius = faceWidth*0.2;
                // add the new view to the window
                [self.view addSubview:mouth];
            }
        }
        
        // }
    }

The Simulator ScreenShot for the Function


[![Face and Feature Detection][1]][1]


  [1]: http://i.stack.imgur.com/AAvQS.png

